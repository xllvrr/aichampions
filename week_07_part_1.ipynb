{"cells":[{"cell_type":"markdown","metadata":{"id":"KZSA4_prhQpa"},"source":["# Notebook: [ Week #7 - Quick Prototyping with Streamlit ]\n","\n","üí°üí°üí° We strongly suggest that you at least go through the following materials in our notes before proceeding with this hands-on session:\n","\n","- *\"Setting up a Streamlit Project with pip and venv\"*\n","\n","- *\"Working with Streamlit\"*\n","\n","---\n","\n","üíé The **best way** to go through this hands-on:\n","- Try not to look at the **Solution Reference** (included in this notebook) or the solution video(s) unless you get stuck for more than 15-20 minutes.\n","\n","- At this point, you should be comfortable with fiddling with the code and resolvings errors on your own."]},{"cell_type":"markdown","metadata":{},"source":["---\n","---"]},{"cell_type":"markdown","metadata":{"id":"MWyyZLIehQpc"},"source":["# Getting Familiar with Streamlit: A Simple Form Submission and Processing in Streamlit\n","\n","- Create a new folder for this hands-on. We will call this new folder as `project folder`.\n","\n","- Create a **new virtual environment** in the `project folder` and activate it.\n","    - The virtual environment must have at least the following packages:\n","      - `streamlit`\n","      - `openai`\n","      - `tiktoken`\n","      - `python-dotenv`\n","      - `pandas`\n","    \n","\n","- Run this script in VS Code to verify that the Streamlit project folder has been set up correctly.\n","\n","    - 1. Create a new file named `main.py` in the root of your project folder and copy the code below into it.\n","\n","    - 2. In the `terminal` of VS Code, execute the command `streamlit run main.py`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Obm3zsoZhQpc"},"outputs":[],"source":["# Set up and run this Streamlit App\n","import streamlit as st\n","\n","# region <--------- Streamlit App Configuration --------->\n","st.set_page_config(\n","    layout=\"centered\",\n","    page_title=\"My Streamlit App\"\n",")\n","# endregion <--------- Streamlit App Configuration --------->\n","\n","st.title(\"Streamlit App\")\n","\n","form = st.form(key=\"form\")\n","form.subheader(\"Prompt\")\n","\n","user_prompt = form.text_area(\"Enter your prompt here\", height=200)\n","\n","if form.form_submit_button(\"Submit\"):\n","    st.toast(\"User Input Submitted - {user_prompt}\")\n","    print(f\"User Input is {user_prompt}\")"]},{"cell_type":"markdown","metadata":{"id":"xoix_6iLhle8"},"source":["---\n","---\n","<br>\n"]},{"cell_type":"markdown","metadata":{"id":"Fb0cNNZChQpd"},"source":["# Developing a Customer Service Bot"]},{"cell_type":"markdown","metadata":{"id":"gDdCdMDbhQpd"},"source":["- The subsequent sections of this notebook contain the instructions for building a simple Q&A Bot using Streamlit.\n","\n","- The Bot relies on the functions that we created in Week 3.\n","\n","    - We suggest that you take a look at Week 3 to understand the overall use case.\n","\n","    - The notebook from Week 3 will also help you understand how we derived the functions that we will be using in this notebook.\n","    \n","    - Note that we did not include all the functions from Week 3 to allow us to better focus on the Streamlit part of the project.\n","\n","\n","- To make it easier to refer to, we have included the functions from Week 3 in this notebook.\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"DnAGQgCvhQpd"},"source":["## Project Structure"]},{"cell_type":"markdown","metadata":{"id":"6F72UCERhQpe"},"source":["![](https://abc-notes.data.tech.gov.sg/resources/img/topic-07-streamlit-llm.png)"]},{"cell_type":"markdown","metadata":{"id":"NxWT921AhQpe"},"source":["---\n","---\n","<br>\n","\n","## Setting Up the Project\n","\n","### Download Required Data"]},{"cell_type":"markdown","metadata":{"id":"j3BS4XZHhQpe"},"source":["- Step 1: Download the the data from the link below\n","    - https://abc-notes.data.tech.gov.sg/resources/data/courses-full.json\n","- Step 2: Create a folder \"data\" in the project folder and copy the `courses-full.json` into the `data` folder."]},{"cell_type":"markdown","metadata":{"id":"nE8fEvmQj7Lc"},"source":["---\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"rxXD_ptihQpe"},"source":["### Copy your `.env` file into the Root of the Project Folder"]},{"cell_type":"markdown","metadata":{"id":"-kCTpl3wkLSl"},"source":["- copy and paste the `.env` file that you have created in `Topic 6` into the root of the project folder.\n","\n","- the `.env` should at least contain the `OPENAI_API_KEY` key-value pair for the purpose of this hands-on."]},{"cell_type":"markdown","metadata":{"id":"Uz6_1C3NkcF5"},"source":["---\n","---\n","<br>\n"]},{"cell_type":"markdown","metadata":{"id":"UHHN3OSlhQpe"},"source":["# Task 1: Convert Helpers Functions into a Python Script that can be Imported"]},{"cell_type":"markdown","metadata":{"id":"j2DvMwQbhQpe"},"source":["The purpose of this task is to create a new Python script named `llm.py` under the folder  `helper_functions` that is located at the root of the project folder.\n","- The `llm.py` script will contain the `helper functions` below:\n","    - 1. `get_embedding`\n","    - 2. `get_completion`\n","    - 3. `get_completion_by_messages`\n","    - 4. `count_tokens`\n","    - 5. `count_tokens_from_messages`\n","\n","\n","- > üí° Note that beside the functions themselve, the script MUST also contain the necessary `import statements` and other dependencies that are required for the functions to work.\n","\n","- This script will allow us to import the functions into the main script `main.py` for the purpose of building Streamlit app."]},{"cell_type":"markdown","metadata":{"id":"TptIS-K3hQpf"},"source":["## Packages to be Imported"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EVseusyxhQpf"},"outputs":[],"source":["import os\n","from dotenv import load_dotenv\n","from openai import OpenAI\n","import tiktoken"]},{"cell_type":"markdown","metadata":{"id":"6U4MB8lchQpf"},"source":["## Load the `.env` file in this new Script"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zsWciWLYhQpf"},"outputs":[],"source":["load_dotenv('.env')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Pass the API Key to the OpenAI Client\n","client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"]},{"cell_type":"markdown","metadata":{"id":"nsJJuqf2hQpf"},"source":["## Function for Generating Embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JP-fbI97hQpf"},"outputs":[],"source":["def get_embedding(input, model='text-embedding-3-small'):\n","    response = client.embeddings.create(\n","        input=input,\n","        model=model\n","    )\n","    return [x.embedding for x in response.data]"]},{"cell_type":"markdown","metadata":{"id":"I5CTQGBqhQpf"},"source":["## Function for Text Generation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aClMiFxJhQpf"},"outputs":[],"source":["# This is the \"Updated\" helper function for calling LLM\n","def get_completion(prompt, model=\"gpt-4o-mini\", temperature=0, top_p=1.0, max_tokens=1024, n=1, json_output=False):\n","    if json_output == True:\n","      output_json_structure = {\"type\": \"json_object\"}\n","    else:\n","      output_json_structure = None\n","\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","    response = client.chat.completions.create( #originally was openai.chat.completions\n","        model=model,\n","        messages=messages,\n","        temperature=temperature,\n","        top_p=top_p,\n","        max_tokens=max_tokens,\n","        n=1,\n","        response_format=output_json_structure,\n","    )\n","    return response.choices[0].message.content"]},{"cell_type":"markdown","metadata":{},"source":["## Function for Text Generation from `Messages`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JeV-efsEhQpf"},"outputs":[],"source":["# Note that this function directly take in \"messages\" as the parameter.\n","def get_completion_by_messages(messages, model=\"gpt-4o-mini\", temperature=0, top_p=1.0, max_tokens=1024, n=1):\n","    response = client.chat.completions.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temperature,\n","        top_p=top_p,\n","        max_tokens=max_tokens,\n","        n=1\n","    )\n","    return response.choices[0].message.content"]},{"cell_type":"markdown","metadata":{"id":"hCrAiMHhhQpf"},"source":["## Functions for Token Counting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RzRfrPUmhQpf"},"outputs":[],"source":["# This function is for calculating the tokens given the \"message\"\n","# ‚ö†Ô∏è This is simplified implementation that is good enough for a rough estimation\n","\n","def count_tokens(text):\n","    encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n","    return len(encoding.encode(text))\n","\n","\n","def count_tokens_from_message(messages):\n","    encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n","    value = ' '.join([x.get('content') for x in messages])\n","    return len(encoding.encode(value))\n"]},{"cell_type":"markdown","metadata":{},"source":["---\n","‚úÖ **CheckPoint**\n","\n","<details>\n","    <summary><font size=\"4\" color=\"darkgreen\"><b>See the Reference Solution (üëÜüèº Click to expand)</b></font></summary>\n","\n","This is one way you can organize your script:\n","\n","------------------------------ START OF SCRIPT ------------------------------\n","\n","```Python\n","import os\n","from dotenv import load_dotenv\n","from openai import OpenAI\n","import tiktoken\n","\n","\n","load_dotenv('.env')\n","\n","# Pass the API Key to the OpenAI Client\n","client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n","\n","def get_embedding(input, model='text-embedding-3-small'):\n","    response = client.embeddings.create(\n","        input=input,\n","        model=model\n","    )\n","    return [x.embedding for x in response.data]\n","\n","\n","# This is the \"Updated\" helper function for calling LLM\n","def get_completion(prompt, model=\"gpt-4o-mini\", temperature=0, top_p=1.0, max_tokens=1024, n=1, json_output=False):\n","    if json_output == True:\n","      output_json_structure = {\"type\": \"json_object\"}\n","    else:\n","      output_json_structure = None\n","\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","    response = client.chat.completions.create( #originally was openai.chat.completions\n","        model=model,\n","        messages=messages,\n","        temperature=temperature,\n","        top_p=top_p,\n","        max_tokens=max_tokens,\n","        n=1,\n","        response_format=output_json_structure,\n","    )\n","    return response.choices[0].message.content\n","\n","\n","# Note that this function directly take in \"messages\" as the parameter.\n","def get_completion_by_messages(messages, model=\"gpt-4o-mini\", temperature=0, top_p=1.0, max_tokens=1024, n=1):\n","    response = client.chat.completions.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temperature,\n","        top_p=top_p,\n","        max_tokens=max_tokens,\n","        n=1\n","    )\n","    return response.choices[0].message.content\n","\n","\n","# This function is for calculating the tokens given the \"message\"\n","# ‚ö†Ô∏è This is simplified implementation that is good enough for a rough estimation\n","def count_tokens(text):\n","    encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n","    return len(encoding.encode(text))\n","\n","\n","def count_tokens_from_message(messages):\n","    encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n","    value = ' '.join([x.get('content') for x in messages])\n","    return len(encoding.encode(value))\n","\n","```\n","\n","------------------------------ END OF SCRIPT ------------------------------\n","</details>"]},{"cell_type":"markdown","metadata":{},"source":["---\n","---\n","<br>"]},{"cell_type":"markdown","metadata":{},"source":["## Testing out the `llm.py` Script\n","\n","1. Copy the code over to replace all the code in the `main.py` script.\n","\n","2. Start the Streamlit app by running `python -m streamlit run main.py` in the terminal."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Set up and run this Streamlit App\n","import streamlit as st\n","from helper_functions import llm # <--- This is the helper function that we have created üÜï\n","\n","\n","# region <--------- Streamlit App Configuration --------->\n","st.set_page_config(\n","    layout=\"centered\",\n","    page_title=\"My Streamlit App\"\n",")\n","# endregion <--------- Streamlit App Configuration --------->\n","\n","st.title(\"Streamlit App\")\n","\n","form = st.form(key=\"form\")\n","form.subheader(\"Prompt\")\n","\n","user_prompt = form.text_area(\"Enter your prompt here\", height=200)\n","\n","if form.form_submit_button(\"Submit\"):\n","    st.toast(f\"User Input Submitted - {user_prompt}\")\n","    response = llm.get_completion(user_prompt) # <--- This calls the helper function that we have created üÜï\n","    st.write(response) # <--- This displays the response generated by the LLM onto the frontend üÜï\n","    print(f\"User Input is {user_prompt}\")"]},{"cell_type":"markdown","metadata":{},"source":["üéâü•≥ Congratulations! You have successfully created a web application that allows users to interect with the LLM!!! üéâü•≥"]},{"cell_type":"markdown","metadata":{"id":"9kfDf9Q0hQpf"},"source":["---\n","---"]},{"cell_type":"markdown","metadata":{"id":"Sx5RqsuKhQpg"},"source":["# Task 2: Writing the Main Logics into Functions"]},{"cell_type":"markdown","metadata":{"id":"_rG4Rk5ohQpg"},"source":["In this task, a new Python script `customer_query_handler.py` in a new folder `logics` at the project's root folder.\n","- This script will contains a list of functions shown the cells below:\n","    - 1. `identify_category_and_courses`\n","    - 2. `get_product_details`\n","    - 3. `generate_response_based_on_course_details`\n","\n","- As a piece of info needed by some of these functions, we also need to have a function to read in the `courses-full.json` file in `data` folder\n","\n","---\n","<br>\n","\n","- üí°üí°üí° Take note that, in the script, you will need to:\n","    - Import the necessary packages.\n","    - Change some of the code in the functions to make it work with the `helper functions` that we have created in the previous task.\n"]},{"cell_type":"markdown","metadata":{"id":"ywAxtAJfhQpg"},"source":["## Function #1: `identify_category_and_courses`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKkQF0dChQpg"},"outputs":[],"source":["category_n_course_name = {'Programming and Development': ['Web Development Bootcamp',\n","                                                          'Introduction to Cloud Computing',\n","                                                          'Advanced Web Development',\n","                                                          'Cloud Architecture Design'],\n","                          'Data Science & AI': ['Data Science with Python',\n","                                                'AI and Machine Learning for Beginners',\n","                                                'Machine Learning with R',\n","                                                'Deep Learning with TensorFlow'],\n","                          'Marketing': ['Digital Marketing Masterclass',\n","                                        'Social Media Marketing Strategy'],\n","                          'Cybersecurity': ['Cybersecurity Fundamentals',\n","                                            'Ethical Hacking for Beginners'],\n","                          'Business and Management': ['Project Management Professional (PMP)√Ç¬Æ Certification Prep',\n","                                                      'Agile Project Management'],\n","                          'Writing and Literature': ['Creative Writing Workshop',\n","                                                     'Advanced Creative Writing'],\n","                          'Design': ['Graphic Design Essentials', 'UI/UX Design Fundamentals']}\n","\n","\n","def identify_category_and_courses(user_message):\n","    delimiter = \"####\"\n","\n","    system_message = f\"\"\"\n","    You will be provided with customer service queries. \\\n","    The customer service query will be enclosed in\n","    the pair of {delimiter}.\n","\n","    Decide if the query is relevant to any specific courses\n","    in the Python dictionary below, which each key is a `category`\n","    and the value is a list of `course_name`.\n","\n","    If there are any relevant course(s) found, output the pair(s) of a) `course_name` the relevant courses and b) the associated `category` into a\n","    list of dictionary object, where each item in the list is a relevant course\n","    and each course is a dictionary that contains two keys:\n","    1) category\n","    2) course_name\n","\n","    {category_n_course_name}\n","\n","    If are no relevant courses are found, output an empty list.\n","\n","    Ensure your response contains only the list of dictionary objects or an empty list, \\\n","    without any enclosing tags or delimiters.\n","    \"\"\"\n","\n","    messages =  [\n","        {'role':'system',\n","         'content': system_message},\n","        {'role':'user',\n","         'content': f\"{delimiter}{user_message}{delimiter}\"},\n","    ]\n","    category_and_product_response_str = get_completion_from_messages(messages)\n","    category_and_product_response_str = category_and_product_response_str.replace(\"'\", \"\\\"\")\n","    category_and_product_response = json.loads(category_and_product_response_str)\n","    return category_and_product_response\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Testing the function to make sure it works\n","# This part should not be included as part of the Python script.\n","\n","user_query = \"I'm interested in learning about artificial intelligence.\"\n","result = identify_category_and_courses(user_query)\n","print(result) "]},{"cell_type":"markdown","metadata":{"id":"ybgEl8xmhQpg"},"source":["## Function #2: `get_product_details`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gt11BCP4hQpg"},"outputs":[],"source":["import json\n","\n","filepath = './data/courses-full.json'\n","# filepath = 'courses-full.json'\n","\n","with open(filepath, 'r') as file:\n","    json_string = file.read()\n","    dict_of_courses = json.loads(json_string)\n","\n","\n","def get_course_details(list_of_category_n_course: list[dict]):\n","    course_names_list = []\n","    for x in category_and_product_response:\n","        course_names_list.append(x.get('course_name')) # x[\"course_name\"]\n","\n","    list_of_course_details = []\n","    for course_name in course_names_list:\n","        list_of_course_details.append(dict_of_courses.get(course_name))\n","    return list_of_course_details"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Testing the function to make sure it works\n","# This part should not be included as part of the Python script.\n","\n","# This is a sample input to test the function\n","sample_input = [{'category': 'Programming and Development','course_name': 'Web Development Bootcamp'},\n","                {'category': 'Data Science & AI', 'course_name': 'Data Science with Python'},\n","                {'category': 'Data Science & AI', 'course_name': 'AI and Machine Learning for Beginners'}]\n","\n","\n","product_details = get_course_details(sample_input)\n","product_details"]},{"cell_type":"markdown","metadata":{"id":"mtGOjitshQpg"},"source":["## Function #3: `generate_response_based_on_course_details`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FkDlB4GMhQpg"},"outputs":[],"source":["def generate_response_based_on_course_details(user_message, product_details):\n","    delimiter = \"####\"\n","\n","    system_message = f\"\"\"\n","    Follow these steps to answer the customer queries.\n","    The customer query will be delimited with a pair {delimiter}.\n","\n","    Step 1:{delimiter} If the user is asking about course, \\\n","    understand the relevant course(s) from the following list.\n","    All available courses shown in the json data below:\n","    {product_details}\n","\n","    Step 2:{delimiter} Use the information about the course to \\\n","    generate the answer for the customer's query.\n","    You must only rely on the facts or information in the course information.\n","    Your response should be as detail as possible and \\\n","    include information that is useful for customer to better understand the course.\n","\n","    Step 3:{delimiter}: Answer the customer in a friendly tone.\n","    Make sure the statements are factually accurate.\n","    Your response should be comprehensive and informative to help the \\\n","    the customers to make their decision.\n","    Complete with details such rating, pricing, and skills to be learnt.\n","    Use Neural Linguistic Programming to construct your response.\n","\n","    Use the following format:\n","    Step 1:{delimiter} <step 1 reasoning>\n","    Step 2:{delimiter} <step 2 reasoning>\n","    Step 3:{delimiter} <step 3 response to customer>\n","\n","    Make sure to include {delimiter} to separate every step.\n","    \"\"\"\n","\n","    messages =  [\n","        {'role':'system',\n","         'content': system_message},\n","        {'role':'user',\n","         'content': f\"{delimiter}{user_message}{delimiter}\"},\n","    ]\n","\n","    response_to_customer = llm.get_completion_by_messages(messages)\n","    response_to_customer = response_to_customer.split(delimiter)[-1]\n","    return response_to_customer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Testing the function to make sure it works\n","# This part should not be included as part of the Python script.\n","\n","user_query = f\"\"\"Do you have any coding or data related courses that are under $1000 \"\"\"\n","\n","response = generate_response_based_on_course_details(user_query, product_details)\n","print(response)"]},{"cell_type":"markdown","metadata":{"id":"j8IgJKtphQph"},"source":["# Task 3: Creating the main function `process_user_query` that calls all the functions above"]},{"cell_type":"markdown","metadata":{},"source":["- Now that we have all the functions in place, we will combine the functions into a main function `process_user_query` in the same script `customer_query_handler.py`.\n","\n","- This main function will call the functions we have created in the previous task to process the user query.\n","  - It acts like a pipeline that combines the functions that act as the `steps` in the pipeline.\n","  - The user query will be passed into this main function and the function will return the response to the user query.\n","\n","- This function will be called in the main script `main.py`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def process_user_message(user_input):\n","    delimiter = \"```\"\n","\n","    # Process 1: If Courses are found, look them up\n","    category_n_course_name = identify_category_and_courses(user_input)\n","    print(\"category_n_course_name : \", category_n_course_name)\n","\n","    # Process 2: Get the Course Details\n","    course_details = get_course_details(category_n_course_name)\n","\n","    # Process 3: Generate Response based on Course Details\n","    reply = generate_response_based_on_course_details(user_input, course_details)\n","\n","    return reply"]},{"cell_type":"markdown","metadata":{},"source":["---\n","‚úÖ **CheckPoint**\n","\n","<details>\n","    <summary><font size=\"4\" color=\"darkgreen\"><b>See the Reference Solution (üëÜüèº Click to expand)</b></font></summary>\n","\n","This is one way you can organize your script:\n","\n","------------------------------ START OF SCRIPT ------------------------------\n","\n","```Python\n","import json\n","from helper_functions import llm\n","\n","category_n_course_name = {'Programming and Development': ['Web Development Bootcamp',\n","                                                          'Introduction to Cloud Computing',\n","                                                          'Advanced Web Development',\n","                                                          'Cloud Architecture Design'],\n","                          'Data Science & AI': ['Data Science with Python',\n","                                                'AI and Machine Learning for Beginners',\n","                                                'Machine Learning with R',\n","                                                'Deep Learning with TensorFlow'],\n","                          'Marketing': ['Digital Marketing Masterclass',\n","                                        'Social Media Marketing Strategy'],\n","                          'Cybersecurity': ['Cybersecurity Fundamentals',\n","                                            'Ethical Hacking for Beginners'],\n","                          'Business and Management': ['Project Management Professional (PMP)√Ç¬Æ Certification Prep',\n","                                                      'Agile Project Management'],\n","                          'Writing and Literature': ['Creative Writing Workshop',\n","                                                     'Advanced Creative Writing'],\n","                          'Design': ['Graphic Design Essentials', 'UI/UX Design Fundamentals']}\n","\n","# Load the JSON file\n","filepath = './data/courses-full.json'\n","with open(filepath, 'r') as file:\n","    json_string = file.read()\n","    dict_of_courses = json.loads(json_string)\n","\n","\n","def identify_category_and_courses(user_message):\n","    delimiter = \"####\"\n","\n","    system_message = f\"\"\"\n","    You will be provided with customer service queries. \\\n","    The customer service query will be enclosed in\n","    the pair of {delimiter}.\n","\n","    Decide if the query is relevant to any specific courses\n","    in the Python dictionary below, which each key is a `category`\n","    and the value is a list of `course_name`.\n","\n","    If there are any relevant course(s) found, output the pair(s) of a) `course_name` the relevant courses and b) the associated `category` into a\n","    list of dictionary object, where each item in the list is a relevant course\n","    and each course is a dictionary that contains two keys:\n","    1) category\n","    2) course_name\n","\n","    {category_n_course_name}\n","\n","    If are no relevant courses are found, output an empty list.\n","\n","    Ensure your response contains only the list of dictionary objects or an empty list, \\\n","    without any enclosing tags or delimiters.\n","    \"\"\"\n","\n","    messages =  [\n","        {'role':'system',\n","         'content': system_message},\n","        {'role':'user',\n","         'content': f\"{delimiter}{user_message}{delimiter}\"},\n","    ]\n","    category_and_product_response_str = llm.get_completion_by_messages(messages)\n","    category_and_product_response_str = category_and_product_response_str.replace(\"'\", \"\\\"\")\n","    category_and_product_response = json.loads(category_and_product_response_str)\n","    return category_and_product_response\n","    \n","\n","def get_course_details(list_of_relevant_category_n_course: list[dict]):\n","    course_names_list = []\n","    for x in list_of_relevant_category_n_course:\n","        course_names_list.append(x.get('course_name')) # x[\"course_name\"]\n","\n","    list_of_course_details = []\n","    for course_name in course_names_list:\n","        list_of_course_details.append(dict_of_courses.get(course_name))\n","    return list_of_course_details\n","\n","\n","def generate_response_based_on_course_details(user_message, product_details):\n","    delimiter = \"####\"\n","\n","    system_message = f\"\"\"\n","    Follow these steps to answer the customer queries.\n","    The customer query will be delimited with a pair {delimiter}.\n","\n","    Step 1:{delimiter} If the user is asking about course, \\\n","    understand the relevant course(s) from the following list.\n","    All available courses shown in the json data below:\n","    {product_details}\n","\n","    Step 2:{delimiter} Use the information about the course to \\\n","    generate the answer for the customer's query.\n","    You must only rely on the facts or information in the course information.\n","    Your response should be as detail as possible and \\\n","    include information that is useful for customer to better understand the course.\n","\n","    Step 3:{delimiter}: Answer the customer in a friendly tone.\n","    Make sure the statements are factually accurate.\n","    Your response should be comprehensive and informative to help the \\\n","    the customers to make their decision.\n","    Complete with details such rating, pricing, and skills to be learnt.\n","    Use Neural Linguistic Programming to construct your response.\n","\n","    Use the following format:\n","    Step 1:{delimiter} <step 1 reasoning>\n","    Step 2:{delimiter} <step 2 reasoning>\n","    Step 3:{delimiter} <step 3 response to customer>\n","\n","    Make sure to include {delimiter} to separate every step.\n","    \"\"\"\n","\n","    messages =  [\n","        {'role':'system',\n","         'content': system_message},\n","        {'role':'user',\n","         'content': f\"{delimiter}{user_message}{delimiter}\"},\n","    ]\n","\n","    response_to_customer = llm.get_completion_by_messages(messages)\n","    response_to_customer = response_to_customer.split(delimiter)[-1]\n","    return response_to_customer\n","\n","\n","def process_user_message(user_input):\n","    delimiter = \"```\"\n","\n","    # Process 1: If Courses are found, look them up\n","    category_n_course_name = identify_category_and_courses(user_input)\n","    print(\"category_n_course_name : \", category_n_course_name)\n","\n","    # Process 2: Get the Course Details\n","    course_details = get_course_details(category_n_course_name)\n","\n","    # Process 3: Generate Response based on Course Details\n","    reply = generate_response_based_on_course_details(user_input, course_details)\n","\n","    # Process 4: Append the response to the list of all messages\n","    return reply\n","```\n","\n","------------------------------ END OF SCRIPT ------------------------------\n","</details>"]},{"cell_type":"markdown","metadata":{"id":"CgA_6-yIhQpk"},"source":["---\n","---\n","\n","# Task 4: Build a Chat Interface for the App"]},{"cell_type":"markdown","metadata":{},"source":["- Modify your `main.py` script to:\n","\n","    1. import the `process_user_message` function from the `customer_query_handler` script.\n","\n","    2. insert the `process_user_message` function into the Streamlit app to process the user query."]},{"cell_type":"markdown","metadata":{},"source":["---\n","‚úÖ **CheckPoint**\n","\n","<details>\n","    <summary><font size=\"4\" color=\"darkgreen\"><b>See the Reference Solution (üëÜüèº Click to expand)</b></font></summary>\n","\n","This is one way you can organize your script:\n","\n","------------------------------ START OF SCRIPT ------------------------------\n","\n","```Python\n","# Set up and run this Streamlit App\n","import streamlit as st\n","# from helper_functions import llm # <--- Not needed anymore. The helper function is now directly called by `customer_query_handler` üÜï\n","from logics.customer_query_handler import process_user_message\n","\n","# region <--------- Streamlit App Configuration --------->\n","st.set_page_config(\n","    layout=\"centered\",\n","    page_title=\"My Streamlit App\"\n",")\n","# endregion <--------- Streamlit App Configuration --------->\n","\n","st.title(\"Streamlit App\")\n","\n","form = st.form(key=\"form\")\n","form.subheader(\"Prompt\")\n","\n","user_prompt = form.text_area(\"Enter your prompt here\", height=200)\n","\n","if form.form_submit_button(\"Submit\"):\n","    st.toast(f\"User Input Submitted - {user_prompt}\")\n","    response = process_user_message(user_prompt) #<--- This calls the `process_user_message` function that we have created üÜï\n","    st.write(response)\n","    print(f\"User Input is {user_prompt}\")\n","```\n","\n","------------------------------ END OF SCRIPT ------------------------------\n","</details>"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"aicamp-3.12.1-win","language":"python","name":"aicamp-3.12.1-win"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
