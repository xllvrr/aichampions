{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6203758e-73eb-4e7b-ad76-d41d604345c6",
      "metadata": {
        "id": "6203758e-73eb-4e7b-ad76-d41d604345c6"
      },
      "source": [
        "---\n",
        "---\n",
        "# Notebook: [ Week #05: Build Your RAG Pipeline with Enhanced Retrieval]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The challenges in this notebook are to implement at least:\n",
        "\n",
        "- 1 x Technique from **Pre-Retrieval Processes**\n",
        "- 1 x Technique from **Retrieval Processes**\n",
        "- 1 x Technique from **Post-Retrieval Processes**\n",
        "\n",
        "---\n",
        "\n",
        "Note:\n",
        "- You may want to challenge yourself to implement those techniques that are covered in our **Course Notes**, but **NOT in the walkthrough of the notebook**.\n",
        "- You can create as many code cells as needed."
      ],
      "metadata": {
        "id": "jvRuSC8AVIPw"
      },
      "id": "jvRuSC8AVIPw"
    },
    {
      "cell_type": "markdown",
      "id": "496cd6c8-1d46-4f5c-9cf6-d6369cc52c1b",
      "metadata": {
        "id": "496cd6c8-1d46-4f5c-9cf6-d6369cc52c1b"
      },
      "source": [
        "## Setup\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8822c1c-6212-416a-aa2a-58d2bf2560c0",
      "metadata": {
        "id": "d8822c1c-6212-416a-aa2a-58d2bf2560c0"
      },
      "outputs": [],
      "source": [
        "# Feel free to install dependencies that you need\n",
        "!pip install openai --quiet\n",
        "!pip install langchain --quiet\n",
        "!pip install langchain_openai --quiet\n",
        "!pip install langchain-community --quiet\n",
        "!pip install unstructured --quiet\n",
        "!pip install pdfminer --quiet\n",
        "!pip install langchain-experimental --quiet\n",
        "!pip install langchain_cohere --quiet\n",
        "!pip install pysbd --quiet\n",
        "!pip install ragas --quiet\n",
        "!pip install pypdf --quiet\n",
        "!pip install lolviz --quiet\n",
        "!pip install chromadb --quiet\n",
        "!pip install pdfminer.six --quiet\n",
        "!pip install tiktoken --quiet\n",
        "!pip install datasets --quiet\n",
        "!pip install langchain-chroma --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37b18427-b945-4641-a0b7-7ca5427226c0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-28T12:00:24.632121Z",
          "start_time": "2024-04-28T12:00:20.490138Z"
        },
        "id": "37b18427-b945-4641-a0b7-7ca5427226c0",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from getpass import getpass\n",
        "\n",
        "API_KEY = getpass(\"Enter your OpenAI API Key\")\n",
        "client = OpenAI(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4d07baa",
      "metadata": {
        "id": "c4d07baa"
      },
      "source": [
        "---\n",
        "\n",
        "## Helper Functions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b03eda8",
      "metadata": {
        "id": "2b03eda8"
      },
      "source": [
        "### Function for Generating Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32f1fb11",
      "metadata": {
        "id": "32f1fb11"
      },
      "outputs": [],
      "source": [
        "def get_embedding(input, model='text-embedding-3-small'):\n",
        "    response = client.embeddings.create(\n",
        "        input=input,\n",
        "        model=model\n",
        "    )\n",
        "    return [x.embedding for x in response.data]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3435d399",
      "metadata": {
        "id": "3435d399"
      },
      "source": [
        "### Function for Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3e807b",
      "metadata": {
        "id": "ce3e807b"
      },
      "outputs": [],
      "source": [
        "# This is the \"Updated\" helper function for calling LLM\n",
        "def get_completion(prompt, model=\"gpt-4o-mini\", temperature=0, top_p=1.0, max_tokens=256, n=1, json_output=False):\n",
        "    if json_output == True:\n",
        "      output_json_structure = {\"type\": \"json_object\"}\n",
        "    else:\n",
        "      output_json_structure = None\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create( #originally was openai.chat.completions\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        max_tokens=max_tokens,\n",
        "        n=1,\n",
        "        response_format=output_json_structure,\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "614c7877",
      "metadata": {
        "id": "614c7877"
      },
      "outputs": [],
      "source": [
        "# This a \"modified\" helper function that we will discuss in this session\n",
        "# Note that this function directly take in \"messages\" as the parameter.\n",
        "def get_completion_by_messages(messages, model=\"gpt-4o-mini\", temperature=0, top_p=1.0, max_tokens=1024, n=1):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        max_tokens=max_tokens,\n",
        "        n=1\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a503547-3c2e-4b63-82a4-33e6da38e7a4",
      "metadata": {
        "id": "2a503547-3c2e-4b63-82a4-33e6da38e7a4"
      },
      "source": [
        "### Functions for Token Counting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7210eb23-50f8-4681-84a2-493f4708501a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-28T12:00:27.880949Z",
          "start_time": "2024-04-28T12:00:27.870060Z"
        },
        "id": "7210eb23-50f8-4681-84a2-493f4708501a"
      },
      "outputs": [],
      "source": [
        "# This function is for calculating the tokens given the \"message\"\n",
        "# ⚠️ This is simplified implementation that is good enough for a rough estimation\n",
        "\n",
        "import tiktoken\n",
        "\n",
        "def count_tokens(text):\n",
        "    encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "def count_tokens_from_message_rough(messages):\n",
        "    encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n",
        "    value = ' '.join([x.get('content') for x in messages])\n",
        "    return len(encoding.encode(value))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43375ba7e5dba945",
      "metadata": {
        "id": "43375ba7e5dba945"
      },
      "source": [
        "## Setting up Credentials & Common Components for LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2039d84463a85a43",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-28T12:00:28.844113Z",
          "start_time": "2024-04-28T12:00:28.841045Z"
        },
        "id": "2039d84463a85a43"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "os.environ[\"OPENAI_API_KEY\"] = API_KEY\n",
        "\n",
        "# embedding model that we will use for the session\n",
        "embeddings_model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
        "\n",
        "# llm to be used in RAG pipeplines in this notebook\n",
        "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0, seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23ea3f59",
      "metadata": {
        "id": "23ea3f59"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d11f82d1",
      "metadata": {
        "id": "d11f82d1"
      },
      "source": [
        "**\\[ Overview of Steps in RAG \\]**\n",
        "\n",
        "- 1. **Document Loading**\n",
        "\t- In this initial step, relevant documents are ingested and prepared for further processing. This process typically occurs offline.\n",
        "- 2. **Splitting & Chunking**\n",
        "\t- The text from the documents is split into smaller chunks or segments.\n",
        "\t- These chunks serve as the building blocks for subsequent stages.\n",
        "- 3. **Storage**\n",
        "\t- The embeddings (vector representations) of these chunks are created and stored in a vector store.\n",
        "\t- These embeddings capture the semantic meaning of the text.\n",
        "- 4. **Retrieval**\n",
        "\t- When an online query arrives, the system retrieves relevant chunks from the vector store based on the query.\n",
        "\t- This retrieval step ensures that the system identifies the most pertinent information.\n",
        "- 5. **Output**\n",
        "\t- Finally, the retrieved chunks are used to generate a coherent response.\n",
        "\t- This output can be in the form of natural language text, summaries, or other relevant content.\n",
        "\n",
        "![](https://abc-notes.data.tech.gov.sg/resources/img/topic-4-rag-overview.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "509e2a85",
      "metadata": {
        "id": "509e2a85"
      },
      "source": [
        "# Setting Up the Common Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb607c36e1f155e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-28T12:00:31.142961Z",
          "start_time": "2024-04-28T12:00:30.800805Z"
        },
        "id": "cb607c36e1f155e"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the notes"
      ],
      "metadata": {
        "id": "l8uk8SuLWJ4i"
      },
      "id": "l8uk8SuLWJ4i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f172c36",
      "metadata": {
        "id": "2f172c36"
      },
      "outputs": [],
      "source": [
        "# Download and unzip into local folder\n",
        "url = \"https://abc-notes.data.tech.gov.sg/resources/data/notes_rag.zip\"\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "response = requests.get(url)\n",
        "z = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "\n",
        "# Take note that the files are unzipped into a folder\n",
        "z.extractall('./notes_rag')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27c59df1",
      "metadata": {
        "id": "27c59df1"
      },
      "source": [
        "## Document Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ef5e533",
      "metadata": {
        "id": "3ef5e533"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e35df19",
      "metadata": {
        "id": "6e35df19"
      },
      "outputs": [],
      "source": [
        "< Your Code Here>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaafe40a90410ca",
      "metadata": {
        "id": "aaafe40a90410ca"
      },
      "source": [
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Technique(s) for Improving Pre-Retrieval Process"
      ],
      "metadata": {
        "id": "rU7yeUllWp5H"
      },
      "id": "rU7yeUllWp5H"
    },
    {
      "cell_type": "code",
      "source": [
        "< Your code here >"
      ],
      "metadata": {
        "id": "cRuS3YQtWjmB"
      },
      "id": "cRuS3YQtWjmB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "<br>\n",
        "\n",
        "# Technique(s) for Improving Retrieval Process"
      ],
      "metadata": {
        "id": "Isg7Z8tTW02-"
      },
      "id": "Isg7Z8tTW02-"
    },
    {
      "cell_type": "code",
      "source": [
        "< Your code here >"
      ],
      "metadata": {
        "id": "OsXN4MYWW5vP"
      },
      "id": "OsXN4MYWW5vP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "<br>\n",
        "\n",
        "# Technique(s) for Improving Post-retrieval Process"
      ],
      "metadata": {
        "id": "UHX6g9qFW7ES"
      },
      "id": "UHX6g9qFW7ES"
    },
    {
      "cell_type": "code",
      "source": [
        "< Your code here >"
      ],
      "metadata": {
        "id": "TrMdCYacW-jd"
      },
      "id": "TrMdCYacW-jd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "aicamp-py3.12",
      "language": "python",
      "name": "aicamp-py3.12"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}